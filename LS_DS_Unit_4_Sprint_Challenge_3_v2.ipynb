{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Autoencoders. In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime locally, on AWS SageMaker, on Colab or on a comparable environment. If something is running longer, double check your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a LSTM classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for object detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe a use case for an autoencoder\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - LSTMSs\n",
        "\n",
        "Use a LSTM to fit a multi-class classification model on Reuters news articles to distinguish topics of articles. The data is already encoded properly for use in a LSTM model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well as the LSTM code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1114
        },
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not change this line. You need the +1 for some reason. \n",
        "max_features = len(word_index.values()) + 1\n",
        "\n",
        "# TODO - your code!\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_QVSlFEAqWJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequence Data Question\n",
        "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
        "\n",
        "\n",
        "\n",
        "## RNNs versus LSTMs\n",
        "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
        "\n",
        "\n",
        "\n",
        "## RNN / LSTM Use Cases\n",
        "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and [ResNet50v2](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2) (pre-trained) to detect which of the images with the `frog_images` subdirectory has a frog in it. Note: You will need to upload the images to Colab. \n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The skimage function below will help you read in all the frog images into memory at once. You should use the preprocessing functions that come with ResnetV2, and you should also resize the images using scikit-image."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread_collection\n",
        "\n",
        "images = imread_collection('./frog_images/*.jpg')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(images))\n",
        "print(type(images[0]), end=\"\\n\\n\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your goal is to validly run ResNet50v2 on the input images - don't worry about tuning or improving the model. Print out the predictions in any way you see fit. \n",
        "\n",
        "*Hint* - ResNet 50v2 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goals:* \n",
        "- Check for other things such as fish.\n",
        "- Print out the image with its predicted label\n",
        "- Wrap everything nicely in well documented fucntions"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, decode_predictions, preprocess_input\n",
        "# TODO - your code!\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FaT07ddW3nHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__ \n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ],
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "- What are the threats posed by AI to our society?\n",
        "- How do you think we can counteract those threats? \n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ],
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ],
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "kernelspec": {
      "display_name": "U4-S2-NNF-DS10",
      "language": "python",
      "name": "u4-s2-nnf-ds10"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}